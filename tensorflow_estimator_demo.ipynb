{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "\n",
    "def input_fn_pandas(df, features, label=None, batch_size=256, num_epochs=5, shuffle=False, queue_capacity_factor=10,\n",
    "                    num_threads=1):\n",
    "    if label is not None:\n",
    "        y = df[label]\n",
    "    else:\n",
    "        y = None\n",
    "    if tf.__version__ >= \"2.0.0\":\n",
    "        return tf.compat.v1.estimator.inputs.pandas_input_fn(df[features], y, batch_size=batch_size,\n",
    "                                                             num_epochs=num_epochs,\n",
    "                                                             shuffle=shuffle,\n",
    "                                                             queue_capacity=batch_size * queue_capacity_factor,\n",
    "                                                             num_threads=num_threads)\n",
    "\n",
    "    return tf.estimator.inputs.pandas_input_fn(df[features], y, batch_size=batch_size, num_epochs=num_epochs,\n",
    "                                               shuffle=shuffle, queue_capacity=batch_size * queue_capacity_factor,\n",
    "                                               num_threads=num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmppue8s09l\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmppue8s09l', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc781181128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/yqstar/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/yqstar/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/yqstar/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/yqstar/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2997: IdentityCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/yqstar/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:3828: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/yqstar/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/yqstar/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/yqstar/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmppue8s09l/model.ckpt.\n",
      "INFO:tensorflow:loss = 155.38919, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 4 into /tmp/tmppue8s09l/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 20.483267.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/yqstar/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-09T10:55:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/yqstar/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmppue8s09l/model.ckpt-4\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-09-10:55:30\n",
      "INFO:tensorflow:Saving dict for global step 4: accuracy = 0.725, accuracy_baseline = 0.725, auc = 0.47021943, auc_precision_recall = 0.2470716, average_loss = 0.77521914, global_step = 4, label/mean = 0.275, loss = 155.04382, precision = 0.0, prediction/mean = 0.076053664, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4: /tmp/tmppue8s09l/model.ckpt-4\n",
      "Loss: 155.043823\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmppue8s09l/model.ckpt-4\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 读取Criteo数据集\n",
    "    data = pd.read_csv('./dataset/criteo_sample.txt')\n",
    "\n",
    "    # Criteo数据集的sparse特征和dense特征字段名\n",
    "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "\n",
    "    # 缺失值填充：sparse_features使用-1填充；dense_features使用0填充;label数据赋值target\n",
    "    data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "    data[dense_features] = data[dense_features].fillna(0, )\n",
    "    target = ['label']\n",
    "\n",
    "    # sparse特征采用LabelEncoder；dense特征采用最大最小化缩放。\n",
    "    for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        data[feat] = lbe.fit_transform(data[feat])\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "\n",
    "    # 列特征处理\n",
    "    dnn_feature_columns = []\n",
    "    linear_feature_columns = []\n",
    "\n",
    "    for i, feat in enumerate(sparse_features):\n",
    "        # tf.feature_column.categorical_column_with_identity(key, num_buckets, default_value=None):将数据转为OneHot数据\n",
    "        # tf.feature_column.embedding_column()：OneHot数据转为embedding数据\n",
    "        # tf.feature_column.numeric_column():实值或数值特征。\n",
    "        dnn_feature_columns.append(tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(feat, data[feat].max() + 1), 4))\n",
    "        linear_feature_columns.append(tf.feature_column.categorical_column_with_identity(feat, data[feat].max() + 1))\n",
    "    for feat in dense_features:\n",
    "        dnn_feature_columns.append(tf.feature_column.numeric_column(feat))\n",
    "        linear_feature_columns.append(tf.feature_column.numeric_column(feat))\n",
    "\n",
    "    # 3.generate input data for model\n",
    "    train, test = train_test_split(data, test_size=0.2, random_state=2021)\n",
    "\n",
    "    # 构建input_fn函数，本示例使用input_fn_pandas函数\n",
    "    train_model_input = input_fn_pandas(train, sparse_features + dense_features, 'label', shuffle=True)\n",
    "    test_model_input = input_fn_pandas(test, sparse_features + dense_features, 'label', shuffle=False)\n",
    "\n",
    "    # 4.Define Model,train,predict and evaluate\n",
    "    model = tf.estimator.DNNClassifier(hidden_units=[117, 64],feature_columns=dnn_feature_columns,activation_fn=tf.nn.sigmoid)\n",
    "\n",
    "    model.train(train_model_input)\n",
    "    # model.evaluate(test_model_input)\n",
    "    pred_ans_iter = model.predict(test_model_input)\n",
    "    ev = model.evaluate(test_model_input)\n",
    "    print(\"Loss: {0:f}\".format(ev[\"loss\"]))\n",
    "    # expected=test[target].values\n",
    "    # template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "    # for pre_dict, expec in zip(pred_ans_iter, expected):\n",
    "    #     class_id = pre_dict['class_ids'][0]\n",
    "    #     probability = pre_dict['probabilities'][class_id]\n",
    "    #     print(template.format(0,\n",
    "    #                           100 * probability, expec))\n",
    "    pred_ans = list(map(lambda x: x['probabilities'], pred_ans_iter))\n",
    "    # predictions = list(itertools.islice(pred_ans_iter,1))\n",
    "    # print('PREDICTIONS',predictions)\n",
    "\n",
    "    # print(\"test LogLoss\", round(log_loss(train[target].values, pred_ans), 4))\n",
    "    # print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.9458044], dtype=float32),\n",
       " array([0.9427527], dtype=float32),\n",
       " array([0.9486576], dtype=float32),\n",
       " array([0.9478439], dtype=float32),\n",
       " array([0.9432604], dtype=float32),\n",
       " array([0.94361943], dtype=float32),\n",
       " array([0.94342005], dtype=float32),\n",
       " array([0.9431041], dtype=float32),\n",
       " array([0.9417645], dtype=float32),\n",
       " array([0.94717264], dtype=float32),\n",
       " array([0.94159955], dtype=float32),\n",
       " array([0.93793714], dtype=float32),\n",
       " array([0.9458681], dtype=float32),\n",
       " array([0.9492917], dtype=float32),\n",
       " array([0.94691885], dtype=float32),\n",
       " array([0.94520605], dtype=float32),\n",
       " array([0.9415462], dtype=float32),\n",
       " array([0.9427545], dtype=float32),\n",
       " array([0.9483095], dtype=float32),\n",
       " array([0.94683874], dtype=float32),\n",
       " array([0.94278324], dtype=float32),\n",
       " array([0.943353], dtype=float32),\n",
       " array([0.9460221], dtype=float32),\n",
       " array([0.9442728], dtype=float32),\n",
       " array([0.94532], dtype=float32),\n",
       " array([0.9469573], dtype=float32),\n",
       " array([0.9437739], dtype=float32),\n",
       " array([0.9394867], dtype=float32),\n",
       " array([0.9475257], dtype=float32),\n",
       " array([0.94423157], dtype=float32),\n",
       " array([0.94605774], dtype=float32),\n",
       " array([0.9426054], dtype=float32),\n",
       " array([0.9448648], dtype=float32),\n",
       " array([0.9454357], dtype=float32),\n",
       " array([0.9477153], dtype=float32),\n",
       " array([0.94378656], dtype=float32),\n",
       " array([0.9405699], dtype=float32),\n",
       " array([0.93905854], dtype=float32),\n",
       " array([0.94271636], dtype=float32),\n",
       " array([0.93757516], dtype=float32),\n",
       " array([0.9458044], dtype=float32),\n",
       " array([0.9427527], dtype=float32),\n",
       " array([0.9486576], dtype=float32),\n",
       " array([0.9478439], dtype=float32),\n",
       " array([0.9432604], dtype=float32),\n",
       " array([0.94361943], dtype=float32),\n",
       " array([0.94342005], dtype=float32),\n",
       " array([0.9431041], dtype=float32),\n",
       " array([0.9417645], dtype=float32),\n",
       " array([0.94717264], dtype=float32),\n",
       " array([0.94159955], dtype=float32),\n",
       " array([0.93793714], dtype=float32),\n",
       " array([0.9458681], dtype=float32),\n",
       " array([0.9492917], dtype=float32),\n",
       " array([0.94691885], dtype=float32),\n",
       " array([0.94520605], dtype=float32),\n",
       " array([0.9415462], dtype=float32),\n",
       " array([0.9427545], dtype=float32),\n",
       " array([0.9483095], dtype=float32),\n",
       " array([0.94683874], dtype=float32),\n",
       " array([0.94278324], dtype=float32),\n",
       " array([0.943353], dtype=float32),\n",
       " array([0.9460221], dtype=float32),\n",
       " array([0.9442728], dtype=float32),\n",
       " array([0.94532], dtype=float32),\n",
       " array([0.9469573], dtype=float32),\n",
       " array([0.9437739], dtype=float32),\n",
       " array([0.9394867], dtype=float32),\n",
       " array([0.9475257], dtype=float32),\n",
       " array([0.94423157], dtype=float32),\n",
       " array([0.94605774], dtype=float32),\n",
       " array([0.9426054], dtype=float32),\n",
       " array([0.9448648], dtype=float32),\n",
       " array([0.9454357], dtype=float32),\n",
       " array([0.9477153], dtype=float32),\n",
       " array([0.94378656], dtype=float32),\n",
       " array([0.9405699], dtype=float32),\n",
       " array([0.93905854], dtype=float32),\n",
       " array([0.94271636], dtype=float32),\n",
       " array([0.93757516], dtype=float32),\n",
       " array([0.9458044], dtype=float32),\n",
       " array([0.9427527], dtype=float32),\n",
       " array([0.9486576], dtype=float32),\n",
       " array([0.9478439], dtype=float32),\n",
       " array([0.9432604], dtype=float32),\n",
       " array([0.94361943], dtype=float32),\n",
       " array([0.94342005], dtype=float32),\n",
       " array([0.9431041], dtype=float32),\n",
       " array([0.9417645], dtype=float32),\n",
       " array([0.94717264], dtype=float32),\n",
       " array([0.94159955], dtype=float32),\n",
       " array([0.93793714], dtype=float32),\n",
       " array([0.9458681], dtype=float32),\n",
       " array([0.9492917], dtype=float32),\n",
       " array([0.94691885], dtype=float32),\n",
       " array([0.94520605], dtype=float32),\n",
       " array([0.9415462], dtype=float32),\n",
       " array([0.9427545], dtype=float32),\n",
       " array([0.9483095], dtype=float32),\n",
       " array([0.94683874], dtype=float32),\n",
       " array([0.94278324], dtype=float32),\n",
       " array([0.943353], dtype=float32),\n",
       " array([0.9460221], dtype=float32),\n",
       " array([0.9442728], dtype=float32),\n",
       " array([0.94532], dtype=float32),\n",
       " array([0.9469573], dtype=float32),\n",
       " array([0.9437739], dtype=float32),\n",
       " array([0.9394867], dtype=float32),\n",
       " array([0.9475257], dtype=float32),\n",
       " array([0.94423157], dtype=float32),\n",
       " array([0.94605774], dtype=float32),\n",
       " array([0.9426054], dtype=float32),\n",
       " array([0.9448648], dtype=float32),\n",
       " array([0.9454357], dtype=float32),\n",
       " array([0.9477153], dtype=float32),\n",
       " array([0.94378656], dtype=float32),\n",
       " array([0.9405699], dtype=float32),\n",
       " array([0.93905854], dtype=float32),\n",
       " array([0.94271636], dtype=float32),\n",
       " array([0.93757516], dtype=float32),\n",
       " array([0.9458044], dtype=float32),\n",
       " array([0.9427527], dtype=float32),\n",
       " array([0.9486576], dtype=float32),\n",
       " array([0.9478439], dtype=float32),\n",
       " array([0.9432604], dtype=float32),\n",
       " array([0.94361943], dtype=float32),\n",
       " array([0.94342005], dtype=float32),\n",
       " array([0.9431041], dtype=float32),\n",
       " array([0.9417645], dtype=float32),\n",
       " array([0.94717264], dtype=float32),\n",
       " array([0.94159955], dtype=float32),\n",
       " array([0.93793714], dtype=float32),\n",
       " array([0.9458681], dtype=float32),\n",
       " array([0.9492917], dtype=float32),\n",
       " array([0.94691885], dtype=float32),\n",
       " array([0.94520605], dtype=float32),\n",
       " array([0.9415462], dtype=float32),\n",
       " array([0.9427545], dtype=float32),\n",
       " array([0.9483095], dtype=float32),\n",
       " array([0.94683874], dtype=float32),\n",
       " array([0.94278324], dtype=float32),\n",
       " array([0.943353], dtype=float32),\n",
       " array([0.9460221], dtype=float32),\n",
       " array([0.9442728], dtype=float32),\n",
       " array([0.94532], dtype=float32),\n",
       " array([0.9469573], dtype=float32),\n",
       " array([0.9437739], dtype=float32),\n",
       " array([0.9394867], dtype=float32),\n",
       " array([0.9475257], dtype=float32),\n",
       " array([0.94423157], dtype=float32),\n",
       " array([0.94605774], dtype=float32),\n",
       " array([0.9426054], dtype=float32),\n",
       " array([0.9448648], dtype=float32),\n",
       " array([0.9454357], dtype=float32),\n",
       " array([0.9477153], dtype=float32),\n",
       " array([0.94378656], dtype=float32),\n",
       " array([0.9405699], dtype=float32),\n",
       " array([0.93905854], dtype=float32),\n",
       " array([0.94271636], dtype=float32),\n",
       " array([0.93757516], dtype=float32),\n",
       " array([0.9458044], dtype=float32),\n",
       " array([0.9427527], dtype=float32),\n",
       " array([0.9486576], dtype=float32),\n",
       " array([0.9478439], dtype=float32),\n",
       " array([0.9432604], dtype=float32),\n",
       " array([0.94361943], dtype=float32),\n",
       " array([0.94342005], dtype=float32),\n",
       " array([0.9431041], dtype=float32),\n",
       " array([0.9417645], dtype=float32),\n",
       " array([0.94717264], dtype=float32),\n",
       " array([0.94159955], dtype=float32),\n",
       " array([0.93793714], dtype=float32),\n",
       " array([0.9458681], dtype=float32),\n",
       " array([0.9492917], dtype=float32),\n",
       " array([0.94691885], dtype=float32),\n",
       " array([0.94520605], dtype=float32),\n",
       " array([0.9415462], dtype=float32),\n",
       " array([0.9427545], dtype=float32),\n",
       " array([0.9483095], dtype=float32),\n",
       " array([0.94683874], dtype=float32),\n",
       " array([0.94278324], dtype=float32),\n",
       " array([0.943353], dtype=float32),\n",
       " array([0.9460221], dtype=float32),\n",
       " array([0.9442728], dtype=float32),\n",
       " array([0.94532], dtype=float32),\n",
       " array([0.9469573], dtype=float32),\n",
       " array([0.9437739], dtype=float32),\n",
       " array([0.9394867], dtype=float32),\n",
       " array([0.9475257], dtype=float32),\n",
       " array([0.94423157], dtype=float32),\n",
       " array([0.94605774], dtype=float32),\n",
       " array([0.9426054], dtype=float32),\n",
       " array([0.9448648], dtype=float32),\n",
       " array([0.9454357], dtype=float32),\n",
       " array([0.9477153], dtype=float32),\n",
       " array([0.94378656], dtype=float32),\n",
       " array([0.9405699], dtype=float32),\n",
       " array([0.93905854], dtype=float32),\n",
       " array([0.94271636], dtype=float32),\n",
       " array([0.93757516], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss by sklearn: 1.2628643221541276.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from math import log # 自然对数为底\n",
    " \n",
    "# 二分类的交叉熵损失函数的计算\n",
    " \n",
    "# y_true为一维，y_pred为二维\n",
    "# 用sklearn的log_loss函数计算损失函数\n",
    "y_true = [0,1]\n",
    "y_pred = [[0.1,0.9], [0.2,0.8]]\n",
    "sk_log_loss = log_loss(y_true,y_pred)\n",
    "print('Loss by sklearn: %s.'%sk_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0 1].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-604ebcb951b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0myht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# -(np.log(0.1)+np.log(0.8))/2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \"\"\"\n\u001b[1;32m    450\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         self._fit(X, handle_unknown=self.handle_unknown,\n\u001b[0;32m--> 424\u001b[0;31m                   force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, handle_unknown, force_all_finite)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         X_list, n_samples, n_features = self._check_X(\n\u001b[0;32m---> 78\u001b[0;31m             X, force_all_finite=force_all_finite)\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[0;34m(self, X, force_all_finite)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# if not a dataframe, do normal check_array validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             X_temp = check_array(X, dtype=None,\n\u001b[0;32m---> 45\u001b[0;31m                                  force_all_finite=force_all_finite)\n\u001b[0m\u001b[1;32m     46\u001b[0m             if (not hasattr(X, 'dtype')\n\u001b[1;32m     47\u001b[0m                     and np.issubdtype(X_temp.dtype, np.str_)):\n",
      "\u001b[0;32m~/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rs_ctr/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    696\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0 1].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.preprocessing import LabelEncoder, MinMaxScaler,OneHotEncoder\n",
    "# # ohe = OneHotEncoder()\n",
    "# # yht = ohe.fit_transform(y_true)\n",
    "# # -(np.log(0.1)+np.log(0.8))/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('tf13_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcfc5ac383e29a4d9e4b55ea7ba22cf581c6948bbd5183707ae4e9a2e91d8d92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
